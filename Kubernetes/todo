Create a cluster and connect with kubectl
aws eks update-kubeconfig --region us-west-2 --name ekscluster

-----------------------------------------------------------------------------------------------------
1. Create a pod
            Kubectl create -f pod.yml
            kubectl get pods
            kubectl delete pods myapp
2. create a replicaset and replication controller(rs and rc)
            kubectl get rc
            kubectl get rs
            kubectl delete rc myapp
            kubectl delete rs myapp
3. create a deployment
4. Create a service
    a. load balancer: a542694a57d6b468f95e7f4e228570dc-1362813864.us-west-2.elb.amazonaws.com/webapp
    b. nodeport : http://35.95.51.255:30001/webapp/
    c. clusterIP: 
Check the application running
------------------------------------------------------------------------------------------------
5. create a configmap
        configmap as environment variable
        configmap as file
             kubectl delete configmaps valuestore
6. Create a secret
        secret from env file 
7. use env variable
            name and value
            kubectl exec <podname> -- printenv
8. create a multi ocntainer
        multple container configuration in single pod
9. create an initcontainer
        init container run first if it is success then all other container will run
10. Daemonset
        same conatiner running on all nodes
11. create a cronjob
        create a job which run every 3min
12. Create a namespace and assign pod, services and deployment into it.
        in metadata, we have to provide namespace details.

13. create a network policies
14. create a ingress rules
15. create a ingress controller
16. create a volume, Volume claim and attach to pod
---------------------------------------------------------------------------------------------------
16. create a kubeconfig file
17. Create a RBAC(Role and Role binding)
18. Create a RBAC(cluster Role and cluster role binding)
19. Create a service account and token for service account
20. liveness and readiness probe